---
title:  "[Paper Review] Chain-of-Thought Prompting Eliits Reasoning in Large Language Models"
excerpt: "Prompting의 중요성"

categories: [Paper Review, NLP]
tags:
  - [AI, 논문리뷰, 공부, Medical AI, NLP, Deep learning]

toc: true
toc_sticky: true

feature_text: |
  ## [Paper Review] 
  Chain-of-Thought Prompting Eliits Reasoning in Large Language Models
feature_image: "https://picsum.photos/2560/600?image=733"
image: "https://picsum.photos/2560/600?image=733"
---

## CoT란 ?

CoT는 "Chain-of-Thought Prompting Eliits Reasoning in Large Language Models"
라는 논문에서 나온 개념으로 Chain-of-Thought는 사고의 사슬이라고 함

사고의 사슬을 직관적으로 이해 해보자면 생각을 이어나가는 체인 정도로 해석될 수 있는데
최종적으로 목표하는 정답을 얻어내기 위해 모델에게 대화의 체인 정도를 알려주는 것으로 이해가 된다.

논문에서는 in-context few-shot learning이라고 언급이 되고 있고
이는 Fine-tuning과 같이 모델 파라미터의 조정 없이 추론 단계에서
더 나은 정답을 나타내주는 방법론이라고 할 수 있다.

본 논문에서는 어떻게 이렇게 간단항 방법이 자연스러운 추론을 이끌어내는지 예시를 통해 알아본다.

<img width="846" alt="스크린샷 2024-05-06 오후 4 58 00" src="https://github.com/Twlee95/Twlee95.github.io/assets/76574427/50bc3212-58eb-46ac-9255-aafdbc9dafb7">

위 그림과 같이 특정 정답 문장을 Prompting 해 줄 경우 모델이 최종 정답에 가까워지는 출력을 하는 것을 볼 수있다.

## 문제의식
LLM은 많은 분야에서 모델의 크기를 키움으로써 큰 성과를 달성했다.
하지만, 모델 크기만을 키우는 것이 산수, 상식, 기호적 추론에서 무조건 좋다는 것은 입증되지 않았다.

## 아이디어
1) 산술적 추론에서는 Rationales를 생성함으로써 큰 성과를 보일 수 있음
* Rationales : 자연어가 문장을 추론할 때 근거로 사용하는 단어,
영화 평판 분류를 할 때 "이 영화는 재미있다"를 입력으로 사용할 경우 "재미있다"가 Rationale에 해당됨

2) "in-context few-shot learning via prompting"
새로운 테스크에 대한 Fine-tuning없이 약간에 Input / Output Example에 대한 Prompt만으로
성능향사에 기여할 수 있다.


## 이전 방식의 제한 사항
1) Rationale Dataset을 만들기는 매우 비용이 큼
2) Traditional few-shot prompting method in Brown et al. (2020)
 - 추론 능력을 요하는 테스크에 대해 취약함
 - 언어모델 규모 증가가 직접적인 성능향상이 되지 않는 경우가 있음



## CoT Prompting이 가지는 매력적인 Properties
1. First, chain of thought, in principle, allows models to decompose multi-step problems into  intermediate steps, which means that additional computation can be allocated to problems  that require more reasoning steps
2. Second, a chain of thought provides an interpretable window into the behavior of the model,  suggesting how it might have arrived at a particular answer and providing opportunities  to debug where the reasoning path went wrong (although fully characterizing a model’s  computations that support an answer remains an open question).  
3. Third, chain-of-thought reasoning can be used for tasks such as math word problems,  commonsense reasoning, and symbolic manipulation, and is potentially applicable (at least  in principle) to any task that humans can solve via language.  
4. Finally, chain-of-thought reasoning can be readily elicited in sufficiently large off-the-shelf  language models simply by including examples of chain of thought sequences into the  exemplars of few-shot prompting.  

## 사용된 데이터셋
  - GSM8K, math word problems
  - SVAMP, Dataset math word  problems with varying structures
  - ASDiv, diverse math word  problems
  - AQuA , algebraic word problems
  - MAWPS,

